{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os \n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"RLxjVtPK8BpooxpLw5eMc83rE\" \n",
    "consumer_secret = \"Fh9PYNdzo5r3XBhf2zdp024AFxdgf6QC2tIfXpoRklOC0hlXI2\"\n",
    "access_key = \"2170385959-ul1qP90wSnR3wK66AGcmBOmXtCCtpy5pc0U7pTH\"\n",
    "access_secret = \"ArtgHqPKFqAgH7re5nDu8isbIqLJKEEgx8HlbOi1EKNnE\"\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAP83KQEAAAAAIPO3olSWrzwclEphyXk14nbU0Qo%3DyzS6EMakjI0S03DyzFHpHRvp74YufOf3SJbwhNGK7rMP3JBSf3\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Tweets from MMDA Twitter Account\n",
    "- Open CSV File\n",
    "- Get the earliest tweet_id\n",
    "- Collect Tweets\n",
    "- Add new Tweets to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweets(username, search_words, count):\n",
    "\n",
    "    try:\n",
    "        tweets = tweepy.Cursor(api.search, q=search_words, tweet_mode=\"extended\").items(count)\n",
    "\n",
    "        tweets_list = [[tweet.id_str, tweet.user.name, tweet.user.verified, tweet.created_at, tweet.full_text] for tweet in tweets if tweet.user.verified and tweet.user.name == username]\n",
    "    \n",
    "        tweets_df = pd.DataFrame(tweets_list)\n",
    "        tweets_df.columns = ['tweet_id','username','verified','date','tweet_content']\n",
    "\n",
    "    except BaseException as e:\n",
    "        print('Failed on status,',str(e))\n",
    "        time.sleep(3)\n",
    "        \n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_premium(username, search_words, date_to, count):\n",
    "\n",
    "    try:\n",
    "        tweets=tweepy.Cursor(api.search_full_archive,environment_name='Scraper', query=search_words, toDate=date_to).items(count)\n",
    "\n",
    "        tweets_list = [[tweet.id_str, tweet.user.name, tweet.user.verified, tweet.created_at, tweet.text] for tweet in tweets]\n",
    "    \n",
    "        tweets_df = pd.DataFrame(tweets_list)\n",
    "        tweets_df.columns = ['tweet_id','username','verified','date','tweet_content']\n",
    "\n",
    "    except BaseException as e:\n",
    "        print('Failed on status,',str(e))\n",
    "        time.sleep(3)\n",
    "        \n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMDA_Tweets.csv is missing\n"
     ]
    }
   ],
   "source": [
    "MAIN_FILE = 'MMDA_Tweets.csv'\n",
    "\n",
    "try:\n",
    "    mmda_df = pd.read_csv(MAIN_FILE,usecols=[1,2,3,4,5])\n",
    "    id_past = datetime.strptime(mmda_df['date'].min(),\"%Y-%m-%d %H:%M:%S\").strftime(\"%Y%m%d%H%M\")\n",
    "    print(id_past)\n",
    "except:\n",
    "    mmda_df = None\n",
    "    print(MAIN_FILE + \" is missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'Official MMDA'\n",
    "search_word = '\"MMDA ALERT:\" from:MMDA'\n",
    "count = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = scrape_tweets(username, search_word, count)\n",
    "merge_df = pd.concat([mmda_df,tweet_df])\n",
    "merge_df.to_csv(MAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------TEST---------#\n",
    "tweet_d_df = scrape_premium(username, search_word, id_past, count)\n",
    "merge_df = pd.concat([mmda_df,tweet_d_df])\n",
    "merge_df.to_csv(MAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
